#!/bin/bash
# ========================================
# SCRIPT DE D√âPLOIEMENT SCRAPER-PRO SEUL
# ========================================
# D√©ploiement de Scraper-Pro sur serveur 2 vCPU / 4 GB RAM
# ========================================

set -e  # Exit on error

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# ========================================
# Fonctions utilitaires
# ========================================

print_header() {
    echo ""
    echo -e "${BLUE}========================================${NC}"
    echo -e "${BLUE}$1${NC}"
    echo -e "${BLUE}========================================${NC}"
    echo ""
}

print_success() {
    echo -e "${GREEN}‚úÖ $1${NC}"
}

print_warning() {
    echo -e "${YELLOW}‚ö†Ô∏è  $1${NC}"
}

print_error() {
    echo -e "${RED}‚ùå $1${NC}"
}

print_info() {
    echo -e "${BLUE}‚ÑπÔ∏è  $1${NC}"
}

# ========================================
# V√©rifications pr√©alables
# ========================================

print_header "üîç V√©rifications Pr√©alables"

# V√©rifier qu'on est root
if [ "$EUID" -ne 0 ]; then
    print_error "Ce script doit √™tre ex√©cut√© en tant que root"
    print_info "Utilisez : sudo $0"
    exit 1
fi

print_success "Ex√©cut√© en tant que root"

# V√©rifier Docker
if ! command -v docker &> /dev/null; then
    print_warning "Docker n'est pas install√©. Installation en cours..."
    curl -fsSL https://get.docker.com -o get-docker.sh
    sh get-docker.sh
    print_success "Docker install√©"
else
    print_success "Docker est install√©"
fi

# V√©rifier Docker Compose
if ! docker compose version &> /dev/null; then
    print_warning "Docker Compose plugin manquant. Installation en cours..."
    apt-get update
    apt-get install -y docker-compose-plugin
    print_success "Docker Compose install√©"
else
    print_success "Docker Compose est install√©"
fi

# ========================================
# Ressources syst√®me
# ========================================

print_header "üìä Ressources Syst√®me"

TOTAL_RAM=$(free -m | grep Mem | awk '{print $2}')
TOTAL_CPU=$(nproc)
TOTAL_DISK=$(df -h / | tail -1 | awk '{print $4}')

echo "CPU   : $TOTAL_CPU vCPU"
echo "RAM   : $TOTAL_RAM MB"
echo "Disk  : $TOTAL_DISK disponible"

if [ "$TOTAL_RAM" -lt 3500 ]; then
    print_warning "RAM < 4 GB d√©tect√©e"
fi

print_success "Ressources syst√®me v√©rifi√©es"

# ========================================
# Configuration du projet
# ========================================

print_header "‚öôÔ∏è  Configuration du Projet"

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_DIR="$(dirname "$SCRIPT_DIR")"

cd "$PROJECT_DIR"

print_info "R√©pertoire du projet : $PROJECT_DIR"

# V√©rifier que docker-compose.scraper-only.yml existe
if [ ! -f "docker-compose.scraper-only.yml" ]; then
    print_error "docker-compose.scraper-only.yml introuvable"
    exit 1
fi

print_success "Fichier docker-compose.scraper-only.yml trouv√©"

# ========================================
# G√©n√©ration des secrets
# ========================================

print_header "üîê Configuration des Secrets"

if [ ! -f ".env" ]; then
    print_info "Cr√©ation du fichier .env"
    touch .env
fi

# Fonction pour g√©n√©rer un secret
generate_secret() {
    openssl rand -base64 32 | tr -d "=+/" | cut -c1-32
}

# V√©rifier si les secrets existent d√©j√†
if ! grep -q "POSTGRES_PASSWORD=" .env || grep -q "POSTGRES_PASSWORD=$" .env; then
    print_info "G√©n√©ration de nouveaux secrets..."

    POSTGRES_USER="scraper_user"
    POSTGRES_PASSWORD=$(generate_secret)
    REDIS_PASSWORD=$(generate_secret)
    API_HMAC_SECRET=$(generate_secret)
    DASHBOARD_PASSWORD=$(generate_secret)

    cat > .env <<EOF
# ========================================
# SCRAPER-PRO - Configuration
# ========================================
# G√©n√©r√© automatiquement le $(date)
# ========================================

# PostgreSQL
POSTGRES_USER=$POSTGRES_USER
POSTGRES_PASSWORD=$POSTGRES_PASSWORD

# Redis
REDIS_PASSWORD=$REDIS_PASSWORD

# API
API_HOST=0.0.0.0
API_PORT=8000
API_HMAC_SECRET=$API_HMAC_SECRET

# Dashboard
DASHBOARD_PASSWORD=$DASHBOARD_PASSWORD

# Scraping (optimis√© pour 2 vCPU)
PROXY_ENABLED=false
DOWNLOAD_DELAY=2.5
CONCURRENT_REQUESTS=3
CONCURRENT_REQUESTS_PER_DOMAIN=1

# Throttling
AUTOTHROTTLE_ENABLED=true
AUTOTHROTTLE_START_DELAY=2
AUTOTHROTTLE_MAX_DELAY=30
SMART_THROTTLE_MIN_DELAY=1.0
SMART_THROTTLE_MAX_DELAY=60.0

# Logs
LOG_LEVEL=INFO
EOF

    print_success "Secrets g√©n√©r√©s et sauvegard√©s dans .env"

    # Sauvegarder les secrets dans un fichier s√©curis√©
    SECRETS_FILE="$HOME/.scraper-secrets-$(date +%Y%m%d_%H%M%S).txt"
    cat > "$SECRETS_FILE" <<EOF
========================================
SCRAPER-PRO SECRETS - $(date)
========================================

POSTGRES_USER=$POSTGRES_USER
POSTGRES_PASSWORD=$POSTGRES_PASSWORD
REDIS_PASSWORD=$REDIS_PASSWORD
API_HMAC_SECRET=$API_HMAC_SECRET
DASHBOARD_PASSWORD=$DASHBOARD_PASSWORD

========================================
URLs d'acc√®s :
========================================
API       : http://$(hostname -I | awk '{print $1}'):8000
Dashboard : http://$(hostname -I | awk '{print $1}'):8501

Health Check : http://$(hostname -I | awk '{print $1}'):8000/health

========================================
IMPORTANT : Sauvegarder ce fichier !
Fichier : $SECRETS_FILE
========================================
EOF

    chmod 600 "$SECRETS_FILE"
    print_success "Secrets sauvegard√©s dans $SECRETS_FILE"
else
    print_info "Secrets d√©j√† configur√©s dans .env"
fi

# ========================================
# Arr√™t des services existants
# ========================================

print_header "üõë Arr√™t des Services Existants"

if docker compose -f docker-compose.scraper-only.yml ps --quiet 2>/dev/null | grep -q .; then
    print_info "Services existants d√©tect√©s. Arr√™t en cours..."
    docker compose -f docker-compose.scraper-only.yml down
    print_success "Services arr√™t√©s"
else
    print_info "Aucun service Scraper-Pro existant"
fi

# ========================================
# Construction des images
# ========================================

print_header "üèóÔ∏è  Construction des Images Docker"

docker compose -f docker-compose.scraper-only.yml build

print_success "Images Docker construites"

# ========================================
# D√©marrage des services
# ========================================

print_header "üöÄ D√©marrage des Services"

docker compose -f docker-compose.scraper-only.yml up -d

# Attendre PostgreSQL
print_info "Attente du d√©marrage de PostgreSQL..."
sleep 10

MAX_RETRIES=30
RETRY_COUNT=0

while ! docker exec scraper-postgres pg_isready -U scraper_user &> /dev/null; do
    RETRY_COUNT=$((RETRY_COUNT+1))
    if [ $RETRY_COUNT -gt $MAX_RETRIES ]; then
        print_error "PostgreSQL n'a pas d√©marr√©"
        exit 1
    fi
    echo -n "."
    sleep 2
done

echo ""
print_success "PostgreSQL est pr√™t"

# V√©rifier Redis
if docker exec scraper-redis redis-cli ping &> /dev/null; then
    print_success "Redis est pr√™t"
fi

# ========================================
# Application des migrations
# ========================================

print_header "üìä Application des Migrations SQL"

if [ -d "db/migrations" ]; then
    for migration in db/migrations/*.sql; do
        if [ -f "$migration" ]; then
            filename=$(basename "$migration")
            print_info "Application de $filename..."
            docker exec -i scraper-postgres psql -U scraper_user -d scraper_db < "$migration" 2>/dev/null || true
            print_success "$filename appliqu√©"
        fi
    done
else
    print_warning "R√©pertoire db/migrations introuvable"
fi

# ========================================
# Health Checks
# ========================================

print_header "üè• V√©rifications de Sant√©"

sleep 5

if curl -sf http://localhost:8000/health > /dev/null; then
    print_success "API Scraper-Pro op√©rationnelle"
else
    print_warning "API ne r√©pond pas encore (attendre 30s)"
fi

if curl -sf http://localhost:8501 > /dev/null; then
    print_success "Dashboard accessible"
else
    print_warning "Dashboard ne r√©pond pas encore"
fi

# ========================================
# √âtat des ressources
# ========================================

print_header "üìä √âtat des Ressources"

echo ""
echo "üñ•Ô∏è  RAM Syst√®me :"
free -h | grep Mem

echo ""
echo "üê≥ Containers Scraper-Pro :"
docker stats --no-stream --format "table {{.Name}}\t{{.MemUsage}}\t{{.CPUPerc}}" | grep scraper

# ========================================
# R√©capitulatif
# ========================================

print_header "‚úÖ D√©ploiement Termin√© !"

SERVER_IP=$(hostname -I | awk '{print $1}')

cat <<EOF

${GREEN}üéâ Scraper-Pro est d√©ploy√© !${NC}

${BLUE}üìç URLs d'acc√®s :${NC}

  üîß API       : http://$SERVER_IP:8000
  üìä Dashboard : http://$SERVER_IP:8501

  ‚úÖ Health    : http://$SERVER_IP:8000/health

${BLUE}üîê Credentials :${NC}

  üìÑ Fichier secrets : ${SECRETS_FILE}

${BLUE}üìä Commandes utiles :${NC}

  # Status des containers
  docker compose -f docker-compose.scraper-only.yml ps

  # Logs en temps r√©el
  docker compose -f docker-compose.scraper-only.yml logs -f

  # Monitoring RAM
  docker stats

  # Red√©marrer
  docker compose -f docker-compose.scraper-only.yml restart

${BLUE}üöÄ Premier test :${NC}

  # Cr√©er un job de scraping
  curl -X POST http://localhost:8000/api/v1/scraping/jobs/simple \\
    -H "Content-Type: application/json" \\
    -d '{
      "source_type": "custom_urls",
      "name": "Test Expat",
      "config": {"urls": ["https://www.expat.com/fr/guide/"]},
      "max_results": 50
    }'

${GREEN}‚úÖ Installation termin√©e avec succ√®s !${NC}

========================================

EOF
