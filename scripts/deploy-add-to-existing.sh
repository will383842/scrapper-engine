#!/bin/bash
# ========================================
# SCRIPT : AJOUTER SCRAPER-PRO √Ä BACKLINK ENGINE
# ========================================
# Ajoute Scraper-Pro sur un serveur qui a d√©j√† Backlink Engine
# Partage PostgreSQL et Redis existants
# ========================================

set -e  # Exit on error

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# ========================================
# Fonctions utilitaires
# ========================================

print_header() {
    echo ""
    echo -e "${BLUE}========================================${NC}"
    echo -e "${BLUE}$1${NC}"
    echo -e "${BLUE}========================================${NC}"
    echo ""
}

print_success() {
    echo -e "${GREEN}‚úÖ $1${NC}"
}

print_warning() {
    echo -e "${YELLOW}‚ö†Ô∏è  $1${NC}"
}

print_error() {
    echo -e "${RED}‚ùå $1${NC}"
}

print_info() {
    echo -e "${BLUE}‚ÑπÔ∏è  $1${NC}"
}

# ========================================
# V√©rifications pr√©alables
# ========================================

print_header "üîç V√©rifications Pr√©alables"

# V√©rifier qu'on est root
if [ "$EUID" -ne 0 ]; then
    print_error "Ce script doit √™tre ex√©cut√© en tant que root"
    print_info "Utilisez : sudo $0"
    exit 1
fi

print_success "Ex√©cut√© en tant que root"

# V√©rifier que Backlink Engine est bien d√©ploy√©
if ! docker ps | grep -q "bl-postgres"; then
    print_error "Container bl-postgres introuvable"
    print_error "Backlink Engine n'est pas d√©ploy√© ou PostgreSQL a un autre nom"
    exit 1
fi

print_success "bl-postgres d√©tect√©"

if ! docker ps | grep -q "bl-redis"; then
    print_error "Container bl-redis introuvable"
    exit 1
fi

print_success "bl-redis d√©tect√©"

# ========================================
# D√©tection des credentials Backlink Engine
# ========================================

print_header "üîê D√©tection des Credentials Backlink Engine"

print_info "Recherche des credentials PostgreSQL et Redis..."

# Essayer de trouver le docker-compose de Backlink Engine
if [ -f "/opt/backlink-engine/docker-compose.yml" ]; then
    BL_COMPOSE_DIR="/opt/backlink-engine"
    print_success "docker-compose Backlink Engine trouv√© : $BL_COMPOSE_DIR"
elif [ -f "$HOME/backlink-engine/docker-compose.yml" ]; then
    BL_COMPOSE_DIR="$HOME/backlink-engine"
    print_success "docker-compose Backlink Engine trouv√© : $BL_COMPOSE_DIR"
else
    print_warning "docker-compose Backlink Engine non trouv√© dans les emplacements standards"
    BL_COMPOSE_DIR=""
fi

# Demander les credentials √† l'utilisateur
echo ""
print_info "Nous avons besoin des credentials PostgreSQL et Redis de Backlink Engine"
echo ""

read -p "üì¶ Nom d'utilisateur PostgreSQL de Backlink Engine [backlink]: " BL_POSTGRES_USER
BL_POSTGRES_USER=${BL_POSTGRES_USER:-backlink}

read -sp "üîë Mot de passe PostgreSQL de Backlink Engine : " BL_POSTGRES_PASSWORD
echo ""

if [ -z "$BL_POSTGRES_PASSWORD" ]; then
    print_error "Le mot de passe PostgreSQL est obligatoire"
    exit 1
fi

read -sp "üîë Mot de passe Redis de Backlink Engine (laisser vide si pas de password) : " BL_REDIS_PASSWORD
echo ""

# V√©rifier la connexion PostgreSQL
print_info "Test de connexion √† PostgreSQL..."
if docker exec bl-postgres psql -U "$BL_POSTGRES_USER" -c "\l" &> /dev/null; then
    print_success "Connexion PostgreSQL r√©ussie"
else
    print_error "Impossible de se connecter √† PostgreSQL avec ces credentials"
    print_info "V√©rifiez le nom d'utilisateur et le mot de passe"
    exit 1
fi

# V√©rifier Redis
print_info "Test de connexion √† Redis..."
if [ -z "$BL_REDIS_PASSWORD" ]; then
    if docker exec bl-redis redis-cli ping &> /dev/null; then
        print_success "Connexion Redis r√©ussie (pas de password)"
    else
        print_warning "Redis n√©cessite peut-√™tre un password"
    fi
else
    if docker exec bl-redis redis-cli -a "$BL_REDIS_PASSWORD" ping &> /dev/null; then
        print_success "Connexion Redis r√©ussie"
    else
        print_error "Impossible de se connecter √† Redis avec ce password"
        exit 1
    fi
fi

# ========================================
# Cr√©ation de la base scraper_db
# ========================================

print_header "üóÑÔ∏è  Cr√©ation de la Base scraper_db"

# V√©rifier si la base existe d√©j√†
if docker exec bl-postgres psql -U "$BL_POSTGRES_USER" -lqt | cut -d \| -f 1 | grep -qw scraper_db; then
    print_warning "La base scraper_db existe d√©j√†"
    read -p "Voulez-vous la recr√©er ? (y/N) " -n 1 -r
    echo
    if [[ $REPLY =~ ^[Yy]$ ]]; then
        docker exec bl-postgres psql -U "$BL_POSTGRES_USER" -c "DROP DATABASE scraper_db;" || true
        print_info "Base scraper_db supprim√©e"
    fi
fi

# Cr√©er la base scraper_db
docker exec bl-postgres psql -U "$BL_POSTGRES_USER" -c "CREATE DATABASE scraper_db;"
print_success "Base scraper_db cr√©√©e"

# Installer les extensions
docker exec bl-postgres psql -U "$BL_POSTGRES_USER" -d scraper_db -c "CREATE EXTENSION IF NOT EXISTS \"uuid-ossp\";"
docker exec bl-postgres psql -U "$BL_POSTGRES_USER" -d scraper_db -c "CREATE EXTENSION IF NOT EXISTS \"pg_trgm\";"
print_success "Extensions PostgreSQL install√©es"

# ========================================
# Configuration Scraper-Pro
# ========================================

print_header "‚öôÔ∏è  Configuration Scraper-Pro"

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_DIR="$(dirname "$SCRIPT_DIR")"

cd "$PROJECT_DIR"

# G√©n√©rer secrets pour Scraper-Pro
generate_secret() {
    openssl rand -base64 32 | tr -d "=+/" | cut -c1-32
}

API_HMAC_SECRET=$(generate_secret)
DASHBOARD_PASSWORD=$(generate_secret)

# Cr√©er le fichier .env
cat > .env <<EOF
# ========================================
# SCRAPER-PRO - Int√©gration avec Backlink Engine
# ========================================
# G√©n√©r√© automatiquement le $(date)
# ========================================

# PostgreSQL (partag√© avec Backlink Engine)
BL_POSTGRES_USER=$BL_POSTGRES_USER
BL_POSTGRES_PASSWORD=$BL_POSTGRES_PASSWORD

# Redis (partag√© avec Backlink Engine)
BL_REDIS_PASSWORD=$BL_REDIS_PASSWORD

# API Scraper-Pro
API_HOST=0.0.0.0
API_PORT=8000
API_HMAC_SECRET=$API_HMAC_SECRET

# Dashboard Scraper-Pro
DASHBOARD_PASSWORD=$DASHBOARD_PASSWORD

# Scraping (optimis√© pour 2 vCPU partag√© avec Backlink Engine)
PROXY_ENABLED=false
DOWNLOAD_DELAY=3.0
CONCURRENT_REQUESTS=2
CONCURRENT_REQUESTS_PER_DOMAIN=1

# Throttling
AUTOTHROTTLE_ENABLED=true
AUTOTHROTTLE_START_DELAY=2
AUTOTHROTTLE_MAX_DELAY=30
SMART_THROTTLE_MIN_DELAY=1.0
SMART_THROTTLE_MAX_DELAY=60.0

# Logs
LOG_LEVEL=INFO
EOF

print_success "Fichier .env cr√©√©"

# Sauvegarder les secrets
SECRETS_FILE="$HOME/.scraper-secrets-$(date +%Y%m%d_%H%M%S).txt"
cat > "$SECRETS_FILE" <<EOF
========================================
SCRAPER-PRO SECRETS - $(date)
========================================

API_HMAC_SECRET=$API_HMAC_SECRET
DASHBOARD_PASSWORD=$DASHBOARD_PASSWORD

PostgreSQL (partag√©) :
  Host     : bl-postgres
  User     : $BL_POSTGRES_USER
  Database : scraper_db

Redis (partag√©) :
  Host     : bl-redis
  Namespace: 1 (Backlink = 0)

========================================
URLs d'acc√®s :
========================================
API       : http://$(hostname -I | awk '{print $1}'):8000
Dashboard : http://$(hostname -I | awk '{print $1}'):8501

Health Check : http://$(hostname -I | awk '{print $1}'):8000/health

========================================
IMPORTANT : Sauvegarder ce fichier !
========================================
EOF

chmod 600 "$SECRETS_FILE"
print_success "Secrets sauvegard√©s dans $SECRETS_FILE"

# ========================================
# V√©rifier le r√©seau Docker
# ========================================

print_header "üåê Configuration R√©seau Docker"

# Trouver le r√©seau de Backlink Engine
BL_NETWORK=$(docker inspect bl-postgres --format '{{range $net,$v := .NetworkSettings.Networks}}{{$net}}{{end}}' | head -1)

if [ -z "$BL_NETWORK" ]; then
    print_error "Impossible de d√©tecter le r√©seau Docker de Backlink Engine"
    exit 1
fi

print_success "R√©seau Backlink Engine d√©tect√© : $BL_NETWORK"

# Modifier docker-compose pour utiliser le bon r√©seau
sed -i "s|backlink-engine_default|$BL_NETWORK|g" docker-compose.add-to-existing.yml

print_success "docker-compose.add-to-existing.yml configur√©"

# ========================================
# Construction des images
# ========================================

print_header "üèóÔ∏è  Construction des Images Docker"

docker compose -f docker-compose.add-to-existing.yml build

print_success "Images Docker construites"

# ========================================
# D√©marrage de Scraper-Pro
# ========================================

print_header "üöÄ D√©marrage de Scraper-Pro"

docker compose -f docker-compose.add-to-existing.yml up -d

print_success "Containers Scraper-Pro d√©marr√©s"

# Attendre que l'API soit pr√™te
print_info "Attente du d√©marrage de l'API (30s)..."
sleep 30

# ========================================
# Application des migrations
# ========================================

print_header "üìä Application des Migrations SQL"

if [ -d "db/migrations" ]; then
    for migration in db/migrations/*.sql; do
        if [ -f "$migration" ]; then
            filename=$(basename "$migration")
            print_info "Application de $filename..."
            docker exec bl-postgres psql -U "$BL_POSTGRES_USER" -d scraper_db < "$migration" 2>/dev/null || true
            print_success "$filename appliqu√©"
        fi
    done
else
    print_warning "R√©pertoire db/migrations introuvable"
fi

# ========================================
# Health Checks
# ========================================

print_header "üè• V√©rifications de Sant√©"

if curl -sf http://localhost:8000/health > /dev/null; then
    print_success "API Scraper-Pro op√©rationnelle"
else
    print_warning "API ne r√©pond pas encore (normal si premier d√©marrage)"
fi

if curl -sf http://localhost:8501 > /dev/null; then
    print_success "Dashboard accessible"
else
    print_warning "Dashboard ne r√©pond pas encore"
fi

# ========================================
# √âtat des ressources
# ========================================

print_header "üìä √âtat des Ressources (Backlink + Scraper)"

echo ""
echo "üñ•Ô∏è  RAM Syst√®me :"
free -h | grep Mem

echo ""
echo "üê≥ Tous les Containers :"
docker stats --no-stream --format "table {{.Name}}\t{{.MemUsage}}\t{{.CPUPerc}}"

# ========================================
# R√©capitulatif
# ========================================

print_header "‚úÖ Scraper-Pro Ajout√© avec Succ√®s !"

SERVER_IP=$(hostname -I | awk '{print $1}')

cat <<EOF

${GREEN}üéâ Scraper-Pro est maintenant d√©ploy√© √† c√¥t√© de Backlink Engine !${NC}

${BLUE}üìç URLs d'acc√®s :${NC}

  üîß Scraper-Pro API       : http://$SERVER_IP:8000
  üìä Scraper-Pro Dashboard : http://$SERVER_IP:8501
  üåê Backlink Engine       : http://$SERVER_IP (port 80)

  ‚úÖ Health Check API      : http://$SERVER_IP:8000/health

${BLUE}üóÑÔ∏è  Base de Donn√©es PostgreSQL (partag√©e) :${NC}

  ‚Ä¢ Backlink Engine : base "backlink" ou similaire
  ‚Ä¢ Scraper-Pro     : base "scraper_db" ‚úÖ

${BLUE}üî¥ Redis (partag√©) :${NC}

  ‚Ä¢ Backlink Engine : namespace 0
  ‚Ä¢ Scraper-Pro     : namespace 1 ‚úÖ

${BLUE}üîê Credentials Scraper-Pro :${NC}

  üìÑ Fichier secrets : ${SECRETS_FILE}

${BLUE}üìä Commandes utiles :${NC}

  # Status tous les containers
  docker ps

  # Logs Scraper-Pro
  docker compose -f docker-compose.add-to-existing.yml logs -f

  # Monitoring RAM global
  docker stats

  # Red√©marrer Scraper-Pro uniquement
  docker compose -f docker-compose.add-to-existing.yml restart

${BLUE}üöÄ Premier test :${NC}

  curl -X POST http://localhost:8000/api/v1/scraping/jobs/simple \\
    -H "Content-Type: application/json" \\
    -d '{
      "source_type": "custom_urls",
      "name": "Test Expat",
      "config": {"urls": ["https://www.expat.com/fr/guide/"]},
      "max_results": 50
    }'

${YELLOW}‚ö†Ô∏è  IMPORTANT :${NC}

  ‚Ä¢ RAM actuelle utilis√©e : ~2.7 GB / 3.7 GB (~73%)
  ‚Ä¢ Si RAM > 85%, r√©duire CONCURRENT_REQUESTS √† 1 dans .env
  ‚Ä¢ Monitorer r√©guli√®rement avec : docker stats

${GREEN}‚úÖ Int√©gration termin√©e avec succ√®s !${NC}

========================================

EOF

print_success "D√©ploiement termin√© !"
