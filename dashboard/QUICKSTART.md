# ğŸš€ Quick Start Guide - Dashboard Final

DÃ©marrez avec le dashboard Scraper-Pro en 5 minutes chrono!

---

## âš¡ Installation Express (Windows)

```powershell
# 1. CrÃ©er un environnement virtuel
python -m venv venv
venv\Scripts\activate

# 2. Installer les dÃ©pendances
pip install -r dashboard\requirements.txt

# 3. Configurer les variables d'environnement
copy .env.example .env
# Ã‰ditez .env avec vos vraies valeurs

# 4. Lancer le dashboard
streamlit run dashboard\app_final.py
```

**Le dashboard sera accessible sur:** `http://localhost:8501`

---

## âš¡ Installation Express (Linux/Mac)

```bash
# 1. CrÃ©er un environnement virtuel
python3 -m venv venv
source venv/bin/activate

# 2. Installer les dÃ©pendances
pip install -r dashboard/requirements.txt

# 3. Configurer les variables d'environnement
cp .env.example .env
# Ã‰ditez .env avec vos vraies valeurs

# 4. Lancer le dashboard
streamlit run dashboard/app_final.py
```

**Le dashboard sera accessible sur:** `http://localhost:8501`

---

## ğŸ³ Installation Express (Docker)

```bash
# 1. Build l'image
docker-compose -f docker-compose.production.yml build dashboard

# 2. Lancer le container
docker-compose -f docker-compose.production.yml up -d dashboard

# 3. VÃ©rifier les logs
docker-compose -f docker-compose.production.yml logs -f dashboard
```

**Le dashboard sera accessible sur:** `http://localhost:8501`

---

## ğŸ”‘ Configuration Minimale (.env)

CrÃ©ez un fichier `.env` Ã  la racine du projet avec ces variables:

```bash
# â•â•â• OBLIGATOIRES â•â•â•
DASHBOARD_PASSWORD=mon_password_admin_securise
API_HMAC_SECRET=mon_secret_hmac_tres_long_et_securise

# â•â•â• DATABASE â•â•â•
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=scraper_db
POSTGRES_USER=scraper_admin
POSTGRES_PASSWORD=mon_password_postgres

# â•â•â• API â•â•â•
SCRAPER_API_URL=http://localhost:8000

# â•â•â• MODE â•â•â•
SCRAPING_MODE=urls_only
```

### ğŸ” GÃ©nÃ©rer des Secrets SÃ©curisÃ©s

```bash
# Linux/Mac
openssl rand -hex 32

# Python (Windows/Linux/Mac)
python -c "import secrets; print(secrets.token_hex(32))"

# PowerShell
-join ((48..57) + (65..90) + (97..122) | Get-Random -Count 64 | % {[char]$_})
```

---

## âœ… VÃ©rification de l'Installation

### Test 1: Connexion au Dashboard

```bash
# Ouvrir dans le navigateur
http://localhost:8501

# Entrer le mot de passe (DASHBOARD_PASSWORD)
# Vous devriez voir 7 onglets:
# - ğŸ“„ Scraping URLs
# - ğŸ” Scraping Google
# - ğŸ‘¥ Contacts & Articles
# - ğŸ“ˆ Statistiques
# - ğŸŒ Proxies Health
# - ğŸ” WHOIS Lookup
# - âš™ï¸ Configuration
```

### Test 2: SantÃ© des Services

Dans la **sidebar**, vÃ©rifiez:
- âœ… API OpÃ©rationnelle (vert)
- âœ… PostgreSQL OK (vert)
- âœ… Redis OK (vert)

Si tout est vert, vous Ãªtes prÃªt! ğŸ‰

### Test 3: Script AutomatisÃ©

```bash
# Lancer le script de test
python dashboard/test_dashboard.py

# Vous devriez voir:
# âœ… Environment Variables - PASSED
# âœ… Python Dependencies - PASSED
# âœ… Dashboard File - PASSED
# âœ… Database Connection - PASSED
# âœ… API Connection - PASSED
```

---

## ğŸ¯ Premiers Pas

### 1. CrÃ©er votre Premier Job

1. Aller dans l'onglet **ğŸ“„ Scraping URLs**
2. Cliquer sur **ğŸ“ Formulaire de CrÃ©ation** (expander)
3. Remplir:
   - **Nom:** "Test Job"
   - **Type:** URLs PersonnalisÃ©es
   - **URLs:** Collez quelques URLs (une par ligne)
   - **CatÃ©gorie:** Choisir ou laisser Auto-detect
   - **Plateforme:** Choisir ou laisser Auto-detect
4. Cliquer **ğŸš€ Lancer le Job**

### 2. Suivre le Job en Temps RÃ©el

- La liste des jobs se rafraÃ®chit automatiquement
- Regardez la colonne **Progress** (barre de progression)
- Status possible: ğŸŸ¢ Running, âœ… Completed, âŒ Failed

### 3. Voir les RÃ©sultats

1. Onglet **ğŸ‘¥ Contacts & Articles** > Sub-tab **ğŸ“§ Contacts**
2. Voir le nombre de contacts scrapÃ©s, validÃ©s, envoyÃ©s
3. Utiliser la recherche pour trouver un contact spÃ©cifique
4. Exporter en CSV si besoin

### 4. Analyser les Stats

1. Onglet **ğŸ“ˆ Statistiques**
2. Voir le graphique de volume (30 derniers jours)
3. Analyser la rÃ©partition par plateforme
4. VÃ©rifier les domaines blacklistÃ©s

---

## ğŸš¨ RÃ©solution Rapide de ProblÃ¨mes

### âŒ "Cannot connect to database"

**Solution:**
```bash
# VÃ©rifier PostgreSQL
docker-compose ps postgres
# Ou
sudo systemctl status postgresql

# VÃ©rifier les variables
echo $POSTGRES_HOST
echo $POSTGRES_PASSWORD

# Tester connexion
psql -h localhost -U scraper_admin -d scraper_db
```

### âŒ "API error: connection refused"

**Solution:**
```bash
# VÃ©rifier l'API
curl http://localhost:8000/health

# VÃ©rifier SCRAPER_API_URL dans .env
cat .env | grep SCRAPER_API_URL
```

### âŒ "Invalid password"

**Solution:**
```bash
# VÃ©rifier DASHBOARD_PASSWORD dans .env
# Pas d'espaces avant/aprÃ¨s
# Exemple correct:
# DASHBOARD_PASSWORD=mon_password_123

# Exemple incorrect:
# DASHBOARD_PASSWORD = mon_password_123  âŒ (espaces)
```

### ğŸŒ Dashboard lent

**Solution:**
```bash
# Cliquer sur le bouton ğŸ”„ RafraÃ®chir
# Ou redÃ©marrer Streamlit
Ctrl+C
streamlit run dashboard/app_final.py
```

---

## ğŸ“š Documentation ComplÃ¨te

Pour aller plus loin:

- **README Complet:** `dashboard/README_FINAL.md`
- **Guide de Migration:** `dashboard/MIGRATION_GUIDE.md`
- **Code Source:** `dashboard/app_final.py`

---

## ğŸ“ Tutoriel VidÃ©o (Ã  venir)

Suivez notre tutoriel vidÃ©o Ã©tape par Ã©tape:
1. Installation de A Ã  Z
2. Configuration des variables d'environnement
3. CrÃ©ation du premier job
4. Analyse des rÃ©sultats
5. Export des donnÃ©es

---

## ğŸ’¡ Astuces Pro

### Raccourcis Clavier Streamlit

- `R` - Relancer l'app (aprÃ¨s modification du code)
- `C` - Ouvrir settings
- `âŒ˜+K` ou `Ctrl+K` - Menu de recherche

### Performance

Pour amÃ©liorer la performance:

1. **Ajoutez des index DB:**
   ```sql
   CREATE INDEX idx_jobs_status ON scraping_jobs(status);
   CREATE INDEX idx_jobs_created ON scraping_jobs(created_at DESC);
   ```

2. **Activez le cache Streamlit:**
   - DÃ©jÃ  activÃ© sur `get_engine()`
   - Ajoutez `@st.cache_data` sur vos queries custom

3. **Limitez les rÃ©sultats:**
   - Toutes les queries ont dÃ©jÃ  des LIMIT (50-100)
   - Utilisez les filtres pour affiner

### Customization

Pour personnaliser le dashboard:

1. **Modifier les couleurs CSS** (ligne 43-124 de `app_final.py`)
2. **Ajouter des mÃ©triques custom** (ligne 380+ pour chaque onglet)
3. **CrÃ©er des onglets custom** (ligne 274)

---

## ğŸ†˜ Support

**ProblÃ¨me non rÃ©solu?**

1. Consulter `dashboard/README_FINAL.md` section Troubleshooting
2. VÃ©rifier les logs: `docker-compose logs dashboard`
3. Tester avec `python dashboard/test_dashboard.py`
4. CrÃ©er une issue GitHub avec:
   - OS et version Python
   - Logs d'erreur complets
   - Steps to reproduce

---

## ğŸ‰ FÃ©licitations!

Vous Ãªtes maintenant prÃªt Ã  utiliser le dashboard Scraper-Pro!

**Prochaines Ã©tapes:**
1. âœ… CrÃ©er vos premiers jobs de scraping
2. âœ… Explorer tous les onglets
3. âœ… Configurer les alertes (Ã  venir)
4. âœ… Passer en mode production (HTTPS, monitoring)

**Bon scraping! ğŸš€**

---

**Made with â¤ï¸ by Ultra-Professional Team**

**Version:** 1.0
**Date:** 2025-02-13
**Support:** README_FINAL.md
