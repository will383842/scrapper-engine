# üöÄ Configuration Dual-App Optimis√©e

## Vue Rapide

Ce package contient une **configuration Docker Compose optimis√©e** pour faire tourner **2 applications** sur un **seul serveur** (2 vCPU / 4 GB RAM) :

1. **Scraper-Pro** (scraping web + extraction de contacts)
2. **Backlink Engine** (votre outil de backlinks)

**√âconomie de RAM** : Les 2 apps partagent PostgreSQL et Redis ‚Üí **~500 MB √©conomis√©s** ‚úÖ

---

## üì¶ Fichiers Cr√©√©s

| Fichier | Description |
|---------|-------------|
| `docker-compose.optimized.yml` | Configuration Docker Compose pour 2 apps |
| `.env.optimized` | Template de configuration avec limites RAM |
| `scripts/postgres-init.sh` | Script d'initialisation PostgreSQL (2 bases) |
| `scripts/deploy-dual-app.sh` | D√©ploiement automatique complet |
| `docs/DUAL_APP_SETUP.md` | Documentation compl√®te (installation, troubleshooting) |

---

## ‚ö° D√©ploiement Rapide (5 minutes)

### Sur votre serveur Helsinki (2 vCPU / 4 GB RAM)

```bash
# 1. SSH vers le serveur
ssh root@VOTRE_IP_HELSINKI

# 2. Cloner le projet
cd /opt
git clone https://github.com/VOTRE-USERNAME/scraper-pro.git
cd scraper-pro

# 3. Rendre le script ex√©cutable
chmod +x scripts/deploy-dual-app.sh
chmod +x scripts/postgres-init.sh

# 4. Lancer le d√©ploiement automatique
./scripts/deploy-dual-app.sh

# ‚úÖ C'est tout ! Le script fait TOUT automatiquement :
#    - Installe Docker/Docker Compose
#    - G√©n√®re tous les secrets (PostgreSQL, Redis, API, etc.)
#    - Cr√©e les 2 bases de donn√©es (scraper_db, backlink_db)
#    - D√©marre tous les services
#    - Applique les migrations
#    - V√©rifie la sant√© des services
#    - Configure le firewall (optionnel)
```

**Temps total : ~5 minutes** ‚è±Ô∏è

---

## üéØ R√©sultat

Apr√®s d√©ploiement, vous aurez :

| Service | Port | URL | RAM |
|---------|------|-----|-----|
| **Scraper-Pro API** | 8000 | http://VOTRE_IP:8000 | ~400 MB |
| **Scraper-Pro Dashboard** | 8501 | http://VOTRE_IP:8501 | ~350 MB |
| **Scraper-Pro Worker** | - | (background) | ~700 MB |
| **Backlink Engine** | 8080 | http://VOTRE_IP:8080 | ~800 MB |
| **PostgreSQL** (partag√©) | 5432 | (interne) | ~500 MB |
| **Redis** (partag√©) | 6379 | (interne) | ~150 MB |
| **TOTAL** | - | - | **~2.9 GB / 4 GB** ‚úÖ |

**Marge disponible : ~1.1 GB (27%)**

---

## üîß Configuration Backlink Engine

Le `docker-compose.optimized.yml` contient une section pour Backlink Engine **√† adapter selon votre configuration** :

```yaml
backlink-engine:
  # ‚ö†Ô∏è Modifier selon votre image Docker
  image: your-backlink-engine:latest

  environment:
    # PostgreSQL (partag√©)
    DB_HOST: postgres
    DB_DATABASE: backlink_db
    DB_USERNAME: shared_user
    DB_PASSWORD: ${POSTGRES_PASSWORD}

    # Redis (partag√©, namespace 1)
    REDIS_HOST: redis
    REDIS_DB: 1

  ports:
    - "8080:80"  # ‚ö†Ô∏è Adapter selon votre port
```

**Si vous n'avez pas encore Backlink Engine**, commentez cette section et d√©ployez uniquement Scraper-Pro.

---

## üìä Commandes Utiles

### V√©rifier l'√©tat des services

```bash
# Liste des containers
docker compose -f docker-compose.optimized.yml ps

# Logs en temps r√©el
docker compose -f docker-compose.optimized.yml logs -f

# Logs d'un service sp√©cifique
docker compose -f docker-compose.optimized.yml logs -f scraper-worker
```

### Monitoring RAM

```bash
# Vue instantan√©e
docker stats --no-stream

# Monitoring continu (rafra√Æchissement toutes les 5s)
watch -n 5 'docker stats --no-stream'

# RAM syst√®me
free -h
```

### Gestion des services

```bash
# Red√©marrer un service
docker compose -f docker-compose.optimized.yml restart scraper-worker

# Arr√™ter tous les services
docker compose -f docker-compose.optimized.yml down

# D√©marrer tous les services
docker compose -f docker-compose.optimized.yml up -d

# Reconstruire et red√©marrer
docker compose -f docker-compose.optimized.yml up -d --build
```

### Acc√®s aux bases de donn√©es

```bash
# Lister les bases de donn√©es
docker exec shared-postgres psql -U shared_user -c "\l"

# Se connecter √† scraper_db
docker exec -it shared-postgres psql -U shared_user -d scraper_db

# Se connecter √† backlink_db
docker exec -it shared-postgres psql -U shared_user -d backlink_db

# V√©rifier Redis
docker exec shared-redis redis-cli -a $REDIS_PASSWORD ping
```

---

## üö® Si la RAM d√©passe 90%

### Option 1 : R√©duire la concurrence du scraper

```bash
nano .env

# Modifier :
CONCURRENT_REQUESTS=2  # Au lieu de 3
CONCURRENT_REQUESTS_PER_DOMAIN=1

# Red√©marrer
docker compose -f docker-compose.optimized.yml restart scraper-worker
```

### Option 2 : D√©sactiver temporairement le Dashboard

```bash
# Stopper le Dashboard (√©conomie : ~350 MB)
docker compose -f docker-compose.optimized.yml stop scraper-dashboard

# Red√©marrer quand n√©cessaire
docker compose -f docker-compose.optimized.yml start scraper-dashboard
```

### Option 3 : Upgrade vers 8 GB RAM

**Sur Hetzner Cloud Console :**
1. Serveur ‚Üí Resize ‚Üí CPX31 (4 vCPU, 8 GB RAM, 11.90‚Ç¨/mois)
2. Apr√®s upgrade, augmenter `CONCURRENT_REQUESTS` √† 6

---

## üìñ Documentation Compl√®te

- **Installation d√©taill√©e** : [docs/DUAL_APP_SETUP.md](docs/DUAL_APP_SETUP.md)
- **R√©f√©rence API** : [docs/API_QUICKSTART.md](docs/API_QUICKSTART.md)
- **Troubleshooting** : [docs/DUAL_APP_SETUP.md](docs/DUAL_APP_SETUP.md#-troubleshooting)
- **Monitoring** : [docs/DUAL_APP_SETUP.md](docs/DUAL_APP_SETUP.md#-monitoring-ram-en-continu)

---

## üîê S√©curit√©

Les secrets sont **g√©n√©r√©s automatiquement** par le script `deploy-dual-app.sh` et sauvegard√©s dans :

```
~/.scraper-secrets-YYYYMMDD_HHMMSS.txt
```

**‚ö†Ô∏è IMPORTANT** : Sauvegardez ce fichier dans un endroit s√ªr (gestionnaire de mots de passe, coffre-fort num√©rique).

---

## üí∞ Co√ªts

| Configuration | Serveur | Proxies | Total/mois |
|---------------|---------|---------|------------|
| **Scraper-Pro + Backlink Engine (URLs)** | 5.99‚Ç¨ | 0‚Ç¨ | **5.99‚Ç¨** ‚úÖ |
| **+ Google Search (futur)** | +11.90‚Ç¨ | +75‚Ç¨ | **92.89‚Ç¨** |
| **Upgrade vers 8 GB** | 11.90‚Ç¨ | 0‚Ç¨ | **11.90‚Ç¨** |

---

## üÜò Support

**Probl√®mes fr√©quents** :

1. **PostgreSQL ne d√©marre pas** ‚Üí V√©rifier `chmod +x scripts/postgres-init.sh`
2. **RAM > 95%** ‚Üí R√©duire `CONCURRENT_REQUESTS` √† 2
3. **Backlink Engine ne se connecte pas** ‚Üí V√©rifier les credentials dans `.env`

**Logs d√©taill√©s** : `docker compose -f docker-compose.optimized.yml logs -f`

---

## ‚úÖ Checklist Rapide

- [ ] Script `deploy-dual-app.sh` ex√©cut√©
- [ ] Secrets sauvegard√©s (`~/.scraper-secrets-*.txt`)
- [ ] 2 bases cr√©√©es (scraper_db, backlink_db)
- [ ] API Scraper-Pro : `curl http://localhost:8000/health` ‚Üí OK
- [ ] Dashboard accessible : `http://VOTRE_IP:8501`
- [ ] RAM < 80% : `docker stats`
- [ ] Firewall configur√© (optionnel)

---

**Votre configuration dual-app optimis√©e est pr√™te ! üéâ**

**Premier test** :

```bash
# Cr√©er un job de scraping (mode dev)
curl -X POST http://localhost:8000/api/v1/scraping/jobs/simple \
  -H "Content-Type: application/json" \
  -d '{
    "source_type": "custom_urls",
    "name": "Test Expat",
    "config": {"urls": ["https://www.expat.com/fr/guide/"]},
    "max_results": 50
  }'

# Voir les logs
curl http://localhost:8000/api/v1/scraping/jobs/1/logs
```

**Bonne utilisation !** üöÄ
