# üöÄ Configuration Dual-App Optimis√©e

## Vue d'ensemble

Ce guide explique comment d√©ployer **Scraper-Pro** ET **Backlink Engine** sur le **m√™me serveur** (2 vCPU / 4 GB RAM) en partageant les services (PostgreSQL + Redis) pour √©conomiser la RAM.

---

## üìä Architecture Optimis√©e

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Serveur : 2 vCPU / 4 GB RAM / 80 GB Disk (5.99‚Ç¨/mois)  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ
‚îÇ  ‚îÇ  SERVICES PARTAG√âS                          ‚îÇ        ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§        ‚îÇ
‚îÇ  ‚îÇ  üì¶ PostgreSQL (500 MB)                     ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ     ‚îú‚îÄ scraper_db   ‚Üí Scraper-Pro          ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ     ‚îî‚îÄ backlink_db  ‚Üí Backlink Engine      ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ                                              ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  üì¶ Redis (150 MB)                          ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ     ‚îú‚îÄ Namespace 0  ‚Üí Scraper-Pro          ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ     ‚îî‚îÄ Namespace 1  ‚Üí Backlink Engine      ‚îÇ        ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ
‚îÇ                                                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ
‚îÇ  ‚îÇ  APPLICATION 1 : SCRAPER-PRO (1.45 GB)     ‚îÇ        ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§        ‚îÇ
‚îÇ  ‚îÇ  üîß API (400 MB)        ‚Üí Port 8000        ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  ‚öôÔ∏è  Worker (700 MB)    ‚Üí Background       ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  üìä Dashboard (350 MB)  ‚Üí Port 8501        ‚îÇ        ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ
‚îÇ                                                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ
‚îÇ  ‚îÇ  APPLICATION 2 : BACKLINK ENGINE (800 MB)  ‚îÇ        ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§        ‚îÇ
‚îÇ  ‚îÇ  üåê App (800 MB)        ‚Üí Port 8080        ‚îÇ        ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ
‚îÇ                                                           ‚îÇ
‚îÇ  Total RAM utilis√©e : ~2.7 GB / 4 GB (~67%)              ‚îÇ
‚îÇ  Marge disponible : ~1.3 GB (33%)                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üéØ Avantages de cette Configuration

| Avantage | Description |
|----------|-------------|
| ‚úÖ **√âconomie RAM** | Services partag√©s = -400-500 MB √©conomis√©s |
| ‚úÖ **√âconomie Co√ªt** | 1 serveur au lieu de 2 = 5.99‚Ç¨/mois |
| ‚úÖ **Simplicit√©** | 1 seul docker-compose pour tout |
| ‚úÖ **Isolation** | 2 bases PostgreSQL distinctes |
| ‚úÖ **Scaling** | Upgrade facile vers 8 GB si besoin |

---

## üõ†Ô∏è Installation Pas-√†-Pas

### 1. Pr√©parer le Serveur

```bash
# SSH vers votre serveur Helsinki
ssh root@VOTRE_IP_HELSINKI

# Mettre √† jour le syst√®me
apt update && apt upgrade -y

# Installer Docker + Docker Compose
curl -fsSL https://get.docker.com -o get-docker.sh
sh get-docker.sh
apt install docker-compose-plugin -y

# V√©rifier l'installation
docker --version
docker compose version
```

### 2. Cloner le Projet Scraper-Pro

```bash
cd /opt
git clone https://github.com/VOTRE-USERNAME/scraper-pro.git
cd scraper-pro

# V√©rifier les fichiers optimis√©s
ls -lh docker-compose.optimized.yml
ls -lh .env.optimized
ls -lh scripts/postgres-init.sh
```

### 3. Configurer les Variables d'Environnement

```bash
# Copier le template optimis√©
cp .env.optimized .env

# G√©n√©rer des mots de passe forts automatiquement
./scripts/generate-secrets.sh

# OU manuellement :
nano .env

# Modifier ces valeurs OBLIGATOIREMENT :
# - POSTGRES_PASSWORD
# - REDIS_PASSWORD
# - API_HMAC_SECRET
# - DASHBOARD_PASSWORD
```

**Script de g√©n√©ration automatique** (recommand√©) :

```bash
cat > /opt/scraper-pro/scripts/generate-secrets.sh <<'EOF'
#!/bin/bash
set -e

echo "üîê G√©n√©ration des secrets cryptographiques..."

# PostgreSQL
POSTGRES_PASSWORD=$(openssl rand -base64 32 | tr -d "=+/" | cut -c1-32)
sed -i "s|POSTGRES_PASSWORD=.*|POSTGRES_PASSWORD=$POSTGRES_PASSWORD|" .env

# Redis
REDIS_PASSWORD=$(openssl rand -base64 32 | tr -d "=+/" | cut -c1-32)
sed -i "s|REDIS_PASSWORD=.*|REDIS_PASSWORD=$REDIS_PASSWORD|" .env

# API HMAC
API_HMAC_SECRET=$(openssl rand -base64 32 | tr -d "=+/" | cut -c1-32)
sed -i "s|API_HMAC_SECRET=.*|API_HMAC_SECRET=$API_HMAC_SECRET|" .env

# Dashboard
DASHBOARD_PASSWORD=$(openssl rand -base64 32 | tr -d "=+/" | cut -c1-32)
sed -i "s|DASHBOARD_PASSWORD=.*|DASHBOARD_PASSWORD=$DASHBOARD_PASSWORD|" .env

# Backlink Engine APP_KEY (format Laravel)
APP_KEY="base64:$(openssl rand -base64 32)"
sed -i "s|APP_KEY=.*|APP_KEY=$APP_KEY|" .env

echo "‚úÖ Secrets g√©n√©r√©s avec succ√®s !"
echo ""
echo "üìÑ Secrets sauvegard√©s dans .env"
echo ""
echo "‚ö†Ô∏è  IMPORTANT : Sauvegarder ces secrets dans un endroit s√ªr :"
echo ""
echo "POSTGRES_PASSWORD=$POSTGRES_PASSWORD"
echo "REDIS_PASSWORD=$REDIS_PASSWORD"
echo "API_HMAC_SECRET=$API_HMAC_SECRET"
echo "DASHBOARD_PASSWORD=$DASHBOARD_PASSWORD"
echo "APP_KEY=$APP_KEY"
EOF

chmod +x /opt/scraper-pro/scripts/generate-secrets.sh
./scripts/generate-secrets.sh
```

### 4. Rendre le Script d'Initialisation PostgreSQL Ex√©cutable

```bash
chmod +x scripts/postgres-init.sh
```

### 5. Adapter la Configuration Backlink Engine

**Si Backlink Engine utilise Laravel/PHP :**

Modifier `docker-compose.optimized.yml` section `backlink-engine` :

```bash
nano docker-compose.optimized.yml

# Rechercher la section "backlink-engine" (ligne ~272)
# Adapter selon votre image Docker ou build
```

**Exemple pour Laravel :**

```yaml
backlink-engine:
  image: votre-registry/backlink-engine:latest
  # OU
  build:
    context: ../backlink-engine
    dockerfile: Dockerfile

  environment:
    DB_CONNECTION: pgsql
    DB_HOST: postgres
    DB_PORT: 5432
    DB_DATABASE: backlink_db
    DB_USERNAME: ${POSTGRES_USER}
    DB_PASSWORD: ${POSTGRES_PASSWORD}

    REDIS_HOST: redis
    REDIS_PORT: 6379
    REDIS_PASSWORD: ${REDIS_PASSWORD}
    REDIS_DB: 1

    APP_ENV: production
    APP_DEBUG: "false"
    APP_KEY: ${APP_KEY}
    APP_URL: ${BACKLINK_URL}

  volumes:
    - ../backlink-engine/storage:/var/www/html/storage
    - ../backlink-engine/.env:/var/www/html/.env
```

### 6. D√©marrer les Services

```bash
# Utiliser le docker-compose optimis√©
docker compose -f docker-compose.optimized.yml up -d

# V√©rifier que tous les containers d√©marrent
docker compose -f docker-compose.optimized.yml ps

# Suivre les logs
docker compose -f docker-compose.optimized.yml logs -f
```

**Output attendu :**

```
NAME                   STATUS              PORTS
shared-postgres        Up 30 seconds       0.0.0.0:5432->5432/tcp
shared-redis           Up 30 seconds       0.0.0.0:6379->6379/tcp
scraper-api            Up 25 seconds       0.0.0.0:8000->8000/tcp
scraper-worker         Up 25 seconds       -
scraper-dashboard      Up 20 seconds       0.0.0.0:8501->8501/tcp
backlink-engine-app    Up 20 seconds       0.0.0.0:8080->80/tcp
```

### 7. Initialiser les Bases de Donn√©es

**Pour Scraper-Pro :**

```bash
# Appliquer les migrations
docker exec scraper-api python -m alembic upgrade head

# OU si vous utilisez les scripts SQL :
docker exec -i shared-postgres psql -U shared_user -d scraper_db < db/migrations/001_initial_schema.sql
docker exec -i shared-postgres psql -U shared_user -d scraper_db < db/migrations/002_add_indexes.sql
# ... r√©p√©ter pour tous les fichiers de migration
```

**Pour Backlink Engine :**

```bash
# Laravel migrations (exemple)
docker exec backlink-engine-app php artisan migrate --force

# OU commande sp√©cifique √† votre Backlink Engine
```

### 8. V√©rifier le Bon Fonctionnement

```bash
# V√©rifier Scraper-Pro API
curl http://localhost:8000/health
# Attendu : {"status":"healthy"}

# V√©rifier PostgreSQL (2 bases cr√©√©es)
docker exec shared-postgres psql -U shared_user -c "\l"
# Attendu : scraper_db et backlink_db dans la liste

# V√©rifier Redis
docker exec shared-redis redis-cli -a $REDIS_PASSWORD ping
# Attendu : PONG

# V√©rifier RAM utilis√©e
docker stats --no-stream
```

**Output attendu (RAM) :**

```
CONTAINER             MEM USAGE / LIMIT
shared-postgres       280MB / 500MB     (56%)
shared-redis          85MB / 150MB      (56%)
scraper-api           320MB / 400MB     (80%)
scraper-worker        580MB / 700MB     (82%)
scraper-dashboard     240MB / 350MB     (68%)
backlink-engine-app   620MB / 800MB     (77%)
-------------------------------------------------
TOTAL                 ~2.1 GB / 4 GB    (52%)
```

---

## üîç Monitoring RAM en Continu

### Script de Monitoring Automatique

```bash
cat > /usr/local/bin/monitor-ram.sh <<'EOF'
#!/bin/bash

echo "=========================================="
echo "üìä RAM Monitoring - Dual Apps"
echo "=========================================="
echo ""

# RAM syst√®me
echo "üñ•Ô∏è  Syst√®me :"
free -h | grep Mem

echo ""
echo "üê≥ Docker Containers :"
docker stats --no-stream --format "table {{.Name}}\t{{.MemUsage}}\t{{.MemPerc}}"

echo ""

# Calcul total RAM Docker
TOTAL_RAM=$(docker stats --no-stream --format "{{.MemUsage}}" | awk '{print $1}' | sed 's/MiB//' | awk '{s+=$1} END {print s}')
echo "üì¶ Total Docker : ${TOTAL_RAM} MB"

# Alerte si > 90%
TOTAL_SYSTEM=$(free -m | grep Mem | awk '{print $2}')
USED_SYSTEM=$(free -m | grep Mem | awk '{print $3}')
PERCENT=$((100 * USED_SYSTEM / TOTAL_SYSTEM))

if [ $PERCENT -gt 90 ]; then
  echo ""
  echo "‚ö†Ô∏è  ALERTE : RAM utilisation √† ${PERCENT}%"
  echo "    Recommandation : R√©duire CONCURRENT_REQUESTS √† 2"
fi

echo "=========================================="
EOF

chmod +x /usr/local/bin/monitor-ram.sh

# Ex√©cuter manuellement
/usr/local/bin/monitor-ram.sh

# OU cron toutes les 5 minutes
(crontab -l 2>/dev/null; echo "*/5 * * * * /usr/local/bin/monitor-ram.sh >> /var/log/ram-monitor.log") | crontab -
```

---

## ‚öôÔ∏è Ajustements selon la Charge

### Si RAM d√©passe 90%

**Option 1 : R√©duire CONCURRENT_REQUESTS**

```bash
nano .env

# Modifier :
CONCURRENT_REQUESTS=2  # Au lieu de 3
CONCURRENT_REQUESTS_PER_DOMAIN=1

# Red√©marrer le scraper
docker compose -f docker-compose.optimized.yml restart scraper-worker
```

**Option 2 : Planifier les T√¢ches Lourdes**

```bash
# Crontab : Scraper la NUIT (2h-6h)
crontab -e

# Ajouter :
0 2 * * * docker exec scraper-api curl -X POST http://localhost:8000/api/v1/scraping/jobs/simple -H "Content-Type: application/json" -d '{"source_type":"custom_urls","name":"Nightly Scrape","config":{"urls":["https://www.expat.com/fr/guide/"]},"max_results":1000}'

# Backlink Engine : T√¢ches le JOUR (10h-18h)
0 10 * * * docker exec backlink-engine-app php artisan backlinks:generate
```

**Option 3 : D√©sactiver Temporairement un Service**

```bash
# Stopper le Dashboard si non utilis√©
docker compose -f docker-compose.optimized.yml stop scraper-dashboard

# √âconomie : ~350 MB RAM
```

---

## üìà Upgrade vers 8 GB RAM (si n√©cessaire)

### Quand upgrader ?

- RAM utilis√©e constamment > 85%
- Scraping lent (throttling excessif)
- Backlink Engine ralenti

### Comment upgrader sur Hetzner ?

```bash
# 1. Via Hetzner Cloud Console
# Serveur ‚Üí Resize ‚Üí CPX31 (4 vCPU, 8 GB, 11.90‚Ç¨/mois)

# 2. Apr√®s upgrade, ajuster la config
nano .env

# Augmenter les ressources :
CONCURRENT_REQUESTS=6  # Au lieu de 3
CONCURRENT_REQUESTS_PER_DOMAIN=2

# 3. D√©commenter le monitoring dans docker-compose.optimized.yml
nano docker-compose.optimized.yml

# D√©commenter :
# - prometheus
# - grafana
# - nginx (reverse proxy)

# 4. Red√©marrer
docker compose -f docker-compose.optimized.yml down
docker compose -f docker-compose.optimized.yml up -d
```

---

## üîê S√©curit√© & Firewall

```bash
# Installer UFW (firewall)
apt install ufw -y

# Autoriser SSH
ufw allow 22/tcp

# Autoriser HTTP/HTTPS (si vous utilisez Nginx)
ufw allow 80/tcp
ufw allow 443/tcp

# Autoriser les ports applicatifs UNIQUEMENT depuis votre IP
ufw allow from VOTRE_IP_BUREAU to any port 8000  # API
ufw allow from VOTRE_IP_BUREAU to any port 8501  # Dashboard
ufw allow from VOTRE_IP_BUREAU to any port 8080  # Backlink Engine

# Activer le firewall
ufw enable

# V√©rifier
ufw status
```

---

## üÜò Troubleshooting

### Probl√®me : Container PostgreSQL ne d√©marre pas

```bash
# V√©rifier les logs
docker compose -f docker-compose.optimized.yml logs postgres

# Erreur fr√©quente : Permission sur postgres-init.sh
chmod +x scripts/postgres-init.sh

# Nettoyer et red√©marrer
docker compose -f docker-compose.optimized.yml down -v
docker compose -f docker-compose.optimized.yml up -d postgres
```

### Probl√®me : RAM d√©passe 95%

```bash
# Solution d'urgence : Red√©marrer containers gourmands
docker compose -f docker-compose.optimized.yml restart scraper-worker

# R√©duire CONCURRENT_REQUESTS √† 2
nano .env
# CONCURRENT_REQUESTS=2

docker compose -f docker-compose.optimized.yml restart scraper-worker scraper-api
```

### Probl√®me : Backlink Engine ne se connecte pas √† PostgreSQL

```bash
# V√©rifier que les 2 bases existent
docker exec shared-postgres psql -U shared_user -c "\l"

# V√©rifier les credentials dans .env
docker exec backlink-engine-app env | grep DB_

# Tester la connexion manuellement
docker exec shared-postgres psql -U shared_user -d backlink_db -c "SELECT 1"
```

---

## üìä Capacit√©s R√©alistes

| M√©trique | Capacit√© (2 vCPU, 4 GB) |
|----------|-------------------------|
| **URLs scrap√©es/jour** | 20,000-30,000 |
| **Contacts collect√©s/jour** | 5,000-10,000 |
| **Backlinks g√©n√©r√©s/jour** | Selon Backlink Engine |
| **Stockage utilis√©** | ~15-25 GB / 80 GB |
| **RAM moyenne** | 2.5-3.0 GB / 4 GB |
| **Uptime** | 99%+ (red√©marrages automatiques) |

---

## üí∞ Co√ªts Totaux

| Sc√©nario | Serveur | Proxies | Total/mois |
|----------|---------|---------|------------|
| **URLs uniquement** | 5.99‚Ç¨ | 0‚Ç¨ | **5.99‚Ç¨** ‚úÖ |
| **URLs + Google (futur)** | 5.99‚Ç¨ + 11.90‚Ç¨ | 75‚Ç¨ | **92.89‚Ç¨** |
| **Upgrade vers 8 GB** | 11.90‚Ç¨ | 0‚Ç¨ | **11.90‚Ç¨** |

---

## ‚úÖ Checklist Finale

- [ ] Docker + Docker Compose install√©s
- [ ] Secrets g√©n√©r√©s automatiquement
- [ ] `postgres-init.sh` ex√©cutable
- [ ] Configuration Backlink Engine adapt√©e
- [ ] Services d√©marr√©s (`docker compose ps`)
- [ ] PostgreSQL : 2 bases cr√©√©es (`\l`)
- [ ] Redis : accessible (`PING`)
- [ ] Scraper API : health check OK
- [ ] RAM monitoring configur√©
- [ ] Firewall activ√© (UFW)
- [ ] Backups automatiques planifi√©s (cron)

---

**Votre configuration dual-app optimis√©e est pr√™te ! üéâ**

Pour plus d'aide, consultez :
- `README.md` : Documentation principale
- `docs/DEPLOYMENT.md` : D√©ploiement production
- `docs/API.md` : R√©f√©rence API
